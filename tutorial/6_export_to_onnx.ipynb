{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.gluon import nn\n",
    "from gluoncv.utils import viz\n",
    "from mxnet import nd\n",
    "\n",
    "'''\n",
    "ConvBlock\n",
    "[Conv2d ─ BN ─ ACTIVATION]\n",
    "'''\n",
    "def ConvBlock(channels, kernel_size, strides, padding, use_bias=False, activation='leaky'):\n",
    "    block = nn.HybridSequential()\n",
    "    block.add(nn.Conv2D(int(channels), kernel_size=kernel_size, strides=strides, padding=padding, use_bias=use_bias))\n",
    "\n",
    "    if not use_bias:\n",
    "        block.add(nn.BatchNorm(in_channels=int(channels)))\n",
    "\n",
    "    if activation == 'leaky':\n",
    "        block.add(nn.LeakyReLU(0.1))\n",
    "\n",
    "    return block\n",
    "\n",
    "\n",
    "'''\n",
    "RedidualBlock\n",
    "[   ┌───────────────────────┐    ]\n",
    "[In ┴ Conv(1x1) ─ Conv(3x3) ┴ out]\n",
    "'''\n",
    "class ResidualBlock(nn.HybridBlock):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvBlock(channels, kernel_size=1, strides=1, padding=0)\n",
    "        self.conv2 = ConvBlock(channels, kernel_size=3, strides=1, padding=1)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        # print('F: ', F)\n",
    "        # print('x: ', x.shape, type(x))\n",
    "\n",
    "        block = self.conv1(x)\n",
    "        block = self.conv2(block)\n",
    "        out = block + x\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CSP(nn.HybridBlock):\n",
    "    def __init__(self, channels, block_size=1):\n",
    "        super(CSP, self).__init__()\n",
    "        self.conv0 = ConvBlock(channels, kernel_size=3, strides=2, padding=1)\n",
    "        self.conv1 = ConvBlock(channels/2, kernel_size=1, strides=1, padding=0)\n",
    "        self.resblocks = self.make_residual_blocks(channels/2, block_size)\n",
    "        \n",
    "        self.conv2 = ConvBlock(channels/2, kernel_size=1, strides=1, padding=0)\n",
    "        self.conv3 = ConvBlock(channels/2, kernel_size=1, strides=1, padding=0)\n",
    "        self.conv4 = ConvBlock(channels, kernel_size=1, strides=1, padding=0)\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.conv0(x)\n",
    "        short_cut = x        \n",
    "        x = self.conv1(x)\n",
    "        x = self.resblocks(x)\n",
    "        x = self.conv2(x)\n",
    "        short_cut = self.conv3(short_cut)\n",
    "        x = F.concat(x, short_cut, dim=1)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def make_residual_blocks(self, channels, block_size):\n",
    "        layer = nn.HybridSequential()\n",
    "        for i in range(block_size):\n",
    "            layer.add(ResidualBlock(channels))        \n",
    "        return layer\n",
    "    \n",
    "class DarkNet(nn.HybridBlock):\n",
    "    def __init__(self, num_classes=1000, input_size=416):\n",
    "        super(DarkNet, self).__init__()\n",
    "        self.layer_num = 0\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.input_layer = nn.Conv2D(channels=32, kernel_size=3, strides=1, padding=1, use_bias=False)\n",
    "\n",
    "        self.layer1 = CSP(64, 1)\n",
    "        self.layer2 = CSP(128, 2)\n",
    "        self.layer3 = CSP(256, 8)\n",
    "        self.layer4 = CSP(512, 8)\n",
    "        self.layer5 = CSP(1024, 4)\n",
    "\n",
    "        self.global_avg_pool = nn.GlobalAvgPool2D()\n",
    "        self.fc = nn.Dense(self.num_classes)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  (1, 5) <class 'mxnet.ndarray.ndarray.NDArray'>\n"
     ]
    }
   ],
   "source": [
    "net = DarkNet(num_classes=5, input_size=224)\n",
    "net.hybridize()\n",
    "net.initialize()\n",
    "x = nd.random.normal(shape=(1, 3, 224, 224))\n",
    "y = net(x)\n",
    "net.export(\"darknet53\")\n",
    "print('y: ', y.shape, type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet.contrib import onnx as onnx_mxnet\n",
    "\n",
    "sym = './darknet53-symbol.json'\n",
    "params = './darknet53-0000.params'\n",
    "\n",
    "# Standard Imagenet input - 3 channels, 224*224\n",
    "input_shape = (1,3,224,224)\n",
    "\n",
    "# Path of the output file\n",
    "onnx_file = './mxnet_exported_darknet53.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pooling: ONNX currently doesn't support pooling_convention. This might lead to shape or accuracy issues. https://github.com/onnx/onnx/issues/549\n"
     ]
    }
   ],
   "source": [
    "converted_model_path = onnx_mxnet.export_model(sym, params, [input_shape], np.float32, onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 5 / 5 (100%)\nMax absolute difference: 0.00081348\nMax relative difference: 3.2020512\n x: array([[ 2.133103e-04, -5.835027e-05,  4.961502e-04, -6.672136e-04,\n        -1.075906e-03]], dtype=float32)\n y: array([[ 0.001027, -0.000461,  0.000998, -0.000159, -0.001   ]],\n      dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a2e21f04912e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ONNX 런타임과 PyTorch에서 연산된 결과값 비교\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exported model has been tested with ONNXRuntime, and the result looks good!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p379/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 5 / 5 (100%)\nMax absolute difference: 0.00081348\nMax relative difference: 3.2020512\n x: array([[ 2.133103e-04, -5.835027e-05,  4.961502e-04, -6.672136e-04,\n        -1.075906e-03]], dtype=float32)\n y: array([[ 0.001027, -0.000461,  0.000998, -0.000159, -0.001   ]],\n      dtype=float32)"
     ]
    }
   ],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"mxnet_exported_darknet53.onnx\")\n",
    "\n",
    "x_1 = x.asnumpy()\n",
    "\n",
    "# ONNX 런타임에서 계산된 결과값\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: x_1}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# ONNX 런타임과 PyTorch에서 연산된 결과값 비교\n",
    "np.testing.assert_allclose(y.asnumpy(), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py379",
   "language": "python",
   "name": "py379"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
